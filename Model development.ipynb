{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64ea67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# We load the library containing functions we made for this project.\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c97a50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with all features : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>EFG%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>35.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  GP   MIN  PTS  FGM  FGA   FG%  3PM  3PA   3P%  EFG%  FTM  \\\n",
       "0   Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7  0.5  2.1  25.0  37.5  1.6   \n",
       "1  Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6  0.7  2.8  23.5  35.1  2.6   \n",
       "2   JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2  0.4  1.7  24.4  46.8  0.9   \n",
       "3      Malik Sealy  58  11.6  5.7  2.3  5.5  42.6  0.1  0.5  22.6  42.7  0.9   \n",
       "4      Matt Geiger  48  11.5  4.5  1.6  3.0  52.4  0.0  0.1   0.0  53.3  1.3   \n",
       "\n",
       "   FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  Target  \n",
       "0  2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3       0  \n",
       "1  3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6       0  \n",
       "2  1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0       0  \n",
       "3  1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0       1  \n",
       "4  1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset with selected features : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>EFG%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>37.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>35.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  GP   MIN  FGA   FG%  EFG%  FTM   FT%  OREB  DREB  AST  \\\n",
       "0   Brandon Ingram  36  27.4  7.6  34.7  37.5  1.6  69.9   0.7   3.4  1.9   \n",
       "1  Andrew Harrison  35  26.9  6.7  29.6  35.1  2.6  76.5   0.5   2.0  3.7   \n",
       "2   JaKarr Sampson  74  15.3  4.7  42.2  46.8  0.9  67.0   0.5   1.7  1.0   \n",
       "3      Malik Sealy  58  11.6  5.5  42.6  42.7  0.9  68.9   1.0   0.9  0.8   \n",
       "4      Matt Geiger  48  11.5  3.0  52.4  53.3  1.3  67.4   1.0   1.5  0.3   \n",
       "\n",
       "   STL  BLK  TOV  Target  \n",
       "0  0.4  0.4  1.3       0  \n",
       "1  1.1  0.5  1.6       0  \n",
       "2  0.5  0.3  1.0       0  \n",
       "3  0.6  0.1  1.0       1  \n",
       "4  0.3  0.4  0.8       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We load our processed data\n",
    "\n",
    "print(\"Dataset with all features : \")\n",
    "df = load_data(data_class=\"Processed\")\n",
    "display(df.head())\n",
    "print(\"\\nDataset with selected features : \")\n",
    "df_selected = load_data(data_class=\"Processed\", data=r\"nba_logreg_selected.csv\")\n",
    "display(df_selected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0db586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All features</th>\n",
       "      <th>Selected features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.701511</td>\n",
       "      <td>0.702307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.690570</td>\n",
       "      <td>0.694647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.703178</td>\n",
       "      <td>0.719639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        All features  Selected features\n",
       "LogisticRegression          0.701511           0.702307\n",
       "DecisionTreeClassifier      0.690570           0.694647\n",
       "KNeighborsClassifier        0.703178           0.719639"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We analyze our features selection impact on models performance.\n",
    "\n",
    "models = [LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"liblinear\", random_state=0), \n",
    "          DecisionTreeClassifier(max_depth=3, class_weight=\"balanced\", random_state=0), \n",
    "          KNeighborsClassifier(20)]\n",
    "compare_features(df, df_selected, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69ab6d",
   "metadata": {},
   "source": [
    "We notice slightly better performance with the selected features. So we will proceed with our models' development using the selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181a8ca",
   "metadata": {},
   "source": [
    "We will proceed with models development. But first, we will define a baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d02ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (1046, 13) (1046,)\n",
      "Test set: (262, 13) (262,)\n"
     ]
    }
   ],
   "source": [
    "# We split our dataset into training and test sets.\n",
    "\n",
    "X = df_selected.iloc[:, 1:-1].to_numpy()\n",
    "Y = df_selected.iloc[:, -1].to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
    "print('Train set:', x_train.shape, y_train.shape)\n",
    "print('Test set:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c904e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We normalize our data.\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "save_scaler(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c4b1bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:07:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:07:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:07:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.705959</td>\n",
       "      <td>0.808742</td>\n",
       "      <td>0.685693</td>\n",
       "      <td>0.705472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.698646</td>\n",
       "      <td>0.762442</td>\n",
       "      <td>0.839422</td>\n",
       "      <td>0.728552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.638865</td>\n",
       "      <td>0.846806</td>\n",
       "      <td>0.556317</td>\n",
       "      <td>0.568621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.720114</td>\n",
       "      <td>0.827814</td>\n",
       "      <td>0.681887</td>\n",
       "      <td>0.714798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.731482</td>\n",
       "      <td>0.843161</td>\n",
       "      <td>0.675038</td>\n",
       "      <td>0.721700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.983352</td>\n",
       "      <td>0.985002</td>\n",
       "      <td>0.992390</td>\n",
       "      <td>0.985632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.882299</td>\n",
       "      <td>0.948402</td>\n",
       "      <td>0.841705</td>\n",
       "      <td>0.873648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.728919</td>\n",
       "      <td>0.800701</td>\n",
       "      <td>0.790715</td>\n",
       "      <td>0.745138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall  F1-score\n",
       "LogisticRegression      0.705959   0.808742  0.685693  0.705472\n",
       "SVC                     0.698646   0.762442  0.839422  0.728552\n",
       "SGDClassifier           0.638865   0.846806  0.556317  0.568621\n",
       "DecisionTreeClassifier  0.720114   0.827814  0.681887  0.714798\n",
       "RandomForestClassifier  0.731482   0.843161  0.675038  0.721700\n",
       "XGBClassifier           0.983352   0.985002  0.992390  0.985632\n",
       "LGBMClassifier          0.882299   0.948402  0.841705  0.873648\n",
       "KNeighborsClassifier    0.728919   0.800701  0.790715  0.745138"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will train our models for a first choice on metrics\n",
    "\n",
    "models = [LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"liblinear\", random_state=0),\n",
    "          SVC(max_iter=1000, random_state=0),\n",
    "          SGDClassifier(class_weight=\"balanced\", random_state=0),\n",
    "          DecisionTreeClassifier(max_depth=3, class_weight=\"balanced\", random_state=0),\n",
    "          RandomForestClassifier(max_depth=3, class_weight=\"balanced\", random_state=0),\n",
    "          XGBClassifier(max_depth=3, use_label_encoder=False, random_state=0),\n",
    "          LGBMClassifier(max_depth=3, objective=\"binary\", class_weight=\"balanced\", random_state=0),\n",
    "          KNeighborsClassifier(20)]\n",
    "comparison_metrics = compare_models_kfolds(x_train, y_train, models, 3)\n",
    "comparison_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b1c04",
   "metadata": {},
   "source": [
    "The scorer function proposed in test.py uses the recall as an evaluation metric for classification. The latter minimizes False Negative error where in our case is representative of missed investments on good players (career length >= 5). However, there is another type of error to consider, False Positive. This error is representative of bad investments in bad players (career length < 5). This last error can be evaluated with the precision metric. Besides, we can take into consideration both error types in our evaluation by using the F1-score, which is the harmonic mean of precision and recall. After initial training of models, we notice that our models respond very well to the false-negative error as they all have a high recall. But they don’t respond to false-positive error as much as the precision is lesser than the recall. Therefore, we will be using the F1-score since both errors have the same weight on the investing process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ddff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:07:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.707345</td>\n",
       "      <td>0.662227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.727172</td>\n",
       "      <td>0.706307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.725023</td>\n",
       "      <td>0.719053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.713278</td>\n",
       "      <td>0.639855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.713249</td>\n",
       "      <td>0.639864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.667663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.643240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.738580</td>\n",
       "      <td>0.669556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Training      Test\n",
       "LogisticRegression      0.707345  0.662227\n",
       "SVC                     0.727172  0.706307\n",
       "SGDClassifier           0.725023  0.719053\n",
       "DecisionTreeClassifier  0.713278  0.639855\n",
       "RandomForestClassifier  0.713249  0.639864\n",
       "XGBClassifier           0.950980  0.667663\n",
       "LGBMClassifier          0.834222  0.643240\n",
       "KNeighborsClassifier    0.738580  0.669556"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will train our models to define a baseline performance.\n",
    "\n",
    "models = [LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"liblinear\", random_state=0),\n",
    "          SVC(max_iter=1000, random_state=0),\n",
    "          SGDClassifier(class_weight=\"balanced\", random_state=0),\n",
    "          DecisionTreeClassifier(max_depth=3, class_weight=\"balanced\", random_state=0),\n",
    "          RandomForestClassifier(max_depth=3, class_weight=\"balanced\", random_state=0),\n",
    "          XGBClassifier(max_depth=3, use_label_encoder=False, random_state=0),\n",
    "          LGBMClassifier(max_depth=3, objective=\"binary\", class_weight=\"balanced\", random_state=0),\n",
    "          KNeighborsClassifier(20)]\n",
    "comparison_models = compare_models(x_train, x_test, y_train, y_test, models, model_store_path=r\"Models\\Baseline\")\n",
    "comparison_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe57a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ranking of our models based on the test F1-score: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier             0.719053\n",
       "SVC                       0.706307\n",
       "KNeighborsClassifier      0.669556\n",
       "XGBClassifier             0.667663\n",
       "LogisticRegression        0.662227\n",
       "LGBMClassifier            0.643240\n",
       "RandomForestClassifier    0.639864\n",
       "DecisionTreeClassifier    0.639855\n",
       "Name: Test, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We rank our models based on their test set F1-score.\n",
    "\n",
    "print(\"The ranking of our models based on the test F1-score: \")\n",
    "comparison_models[\"Test\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7c279",
   "metadata": {},
   "source": [
    "We note that the baseline performance on the test set (f1-score) is 0.70. </br>We will tune the top two models to finally choose the one with the best performance:\n",
    "- Stochastic Gradient Descent Classifier\n",
    "- Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3226ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params with F1-score = 0.716337903007997 :\n",
      "\n",
      "{'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 25, 'penalty': 'l2', 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "# We fine-tune the Stochastic Gradient Descent Classifier.\n",
    "\n",
    "grid_param = {\"loss\": [\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"], \"penalty\": ['l2'],\n",
    "              \"max_iter\": [10, 25, 50, 100], \"alpha\": [0.1, 0.05, 0.025, 0.01, 0.005, 0.002, 0.001], \"random_state\": [0]}\n",
    "best_param_sgd = tune_model(x_train, y_train, SGDClassifier, 3, grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892a6974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params with F1-score = 0.7152732215716958 :\n",
      "\n",
      "{'C': 10, 'coef0': 0.001, 'gamma': 1, 'kernel': 'rbf', 'max_iter': 500, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "# We fine-tune the Support Vector Classifier.\n",
    "\n",
    "grid_param = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100], \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "              \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001], \"coef0\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              \"max_iter\": [10, 100, 250, 500], \"random_state\": [0]}\n",
    "best_param_svc = tune_model(x_train, y_train, SVC, 3, grid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1af92b95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.720697</td>\n",
       "      <td>0.735123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.751524</td>\n",
       "      <td>0.716275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Training      Test\n",
       "SGDClassifier  0.720697  0.735123\n",
       "SVC            0.751524  0.716275"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will compare our fine-tuned models.\n",
    "\n",
    "models = [SGDClassifier(**best_param_sgd), SVC(**best_param_svc)]\n",
    "comparison_models = compare_models(x_train, x_test, y_train, y_test, models,\n",
    "                                   model_store_path=r\"Models\\TunedModels\")\n",
    "comparison_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a48edd",
   "metadata": {},
   "source": [
    "The Stochastic Gradient Descent Classifier showed a higher performance compared to other models. So we will choose it in our application deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9980871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.62      0.63        97\n",
      "         1.0       0.78      0.81      0.79       165\n",
      "\n",
      "    accuracy                           0.74       262\n",
      "   macro avg       0.72      0.71      0.71       262\n",
      "weighted avg       0.73      0.74      0.74       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will simulate the whole prediction process and get the final classification report.\n",
    "\n",
    "data = load_data()\n",
    "data.rename(columns={\"3P Made\": \"3PM\", \"TARGET_5Yrs\": \"Target\"}, inplace=True)\n",
    "data.fillna(0, inplace=True)\n",
    "duplicate_idx = data[data.duplicated(subset=data.columns[1:-1], keep=False)].index\n",
    "data.iloc[duplicate_idx, -1] = data.iloc[duplicate_idx].groupby(list(data.columns[1:-1]))[\"Target\"] \\\n",
    "    .transform(lambda x: 1 * (x.mean() >= 0.5) + 0 * (x.mean() < 0.5))\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.insert(loc=10, column=\"EFG%\", value=round((data[\"FGM\"] + 0.5 * data[\"3PM\"]) * 100 / data[\"FGA\"], 1))\n",
    "data = data[[\"Name\", \"GP\", \"MIN\", \"FGA\", \"FG%\", \"EFG%\", \"FTM\",\n",
    "             \"FT%\", \"OREB\", \"DREB\", \"AST\", \"STL\", \"BLK\", \"TOV\", \"Target\"]]\n",
    "X = data.iloc[:, 1:-1].to_numpy()\n",
    "Y = data.iloc[:, -1].to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
    "pipeline = Pipeline([('scaler', MinMaxScaler()), ('Classifier', SGDClassifier(**best_param_sgd))])\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f387f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the final pipeline.\n",
    "\n",
    "save_model(pipeline, model_store_path=r\"Models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
